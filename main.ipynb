{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ef71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter v√¶rdier er np.random\n",
    "class FNN():\n",
    "    def __init__(self, x, y, batch_size = 32, epoch = 5000, lr = 0.01, hidden_layer_size = 16):\n",
    "        self.input = np.array(x)\n",
    "        self.target = np.array(y)\n",
    "\n",
    "        self.input_dim = x.shape[1]\n",
    "        self.output_dim = y.shape[1]\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = epoch\n",
    "        self.learning_rate = lr\n",
    "        self.weight_hidden = np.random.randn(self.input_dim, self.hidden_layer_size)\n",
    "        self.bias_hidden = np.random.randn(self.hidden_layer_size)\n",
    "        self.weight_output = np.random.randn(self.hidden_layer_size, self.output_dim)\n",
    "        self.bias_output = np.random.randn(self.output_dim)\n",
    "\n",
    "    def ReLU(self,x):\n",
    "        return np.maximum(0,x)\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def leaky_ReLU(self, x):\n",
    "        return np.maximum(0, x) + 0.1 * np.minimum(0, x)\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "    \n",
    "    def MSE(self, obs,preds):\n",
    "        return 1/len(obs) * np.sum((obs-preds)**2)\n",
    "    \n",
    "    def CrossentropyLoss(self, obs, preds):\n",
    "        return -(obs)\n",
    "\n",
    "    \n",
    "    def forward_pass(self):\n",
    "        self.hidden1 = self.input @ self.weight_hidden + self.bias_hidden\n",
    "        self.activation1 = self.ReLU(self.hidden1)\n",
    "        self.hidden2 = self.activation1 @ self.weight_output + self.bias_output\n",
    "        output = self.hidden2\n",
    "        return output\n",
    "    \n",
    "\n",
    "    def backward_pass(self):\n",
    "        ###TBD###\n",
    "        # forward pass\n",
    "        #Mini batch gradient descent\n",
    "        #Backpropagation\n",
    "\n",
    "    def train(self):\n",
    "        #TBD\n",
    "        #Train loop\n",
    "        #update weights\n",
    "\n",
    "    def pred(self):\n",
    "        #TBD\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
